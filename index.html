---
redirect_from: diffdiffdepth/
---

<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-KyZXEAg3QhqLMpG8r+8fhAXLRk2vvoC2f3B09zVXn8CA5QIVfZOJ3BCsw2P0p/We" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/js/bootstrap.bundle.min.js" integrity="sha384-U1DAWAznBHeqEIlVSCgzq+c9gqGAJn5c/t99JyeKa9xxaYpSvHU5awsuZVVFIhvj" crossorigin="anonymous"></script>
    <!-- <link rel="stylesheet" href="styles.css" type="text/css"> -->

    <style>
      @font-face {
          font-family: aaargh;
          src: url(fonts/Aaargh.ttf);
      }

      h1, h2, h3, h4, h5, h6 { 
          font-family: Aaargh;
          margin-top: 2rem;
      }


      p {
          text-align: justify;

          -webkit-hyphens: auto;
          -webkit-hyphenate-limit-before: 3;
          -webkit-hyphenate-limit-after: 3;
          -webkit-hyphenate-limit-chars: 6 3 3;
          -webkit-hyphenate-limit-lines: 2;
          -webkit-hyphenate-limit-last: always;
          -webkit-hyphenate-limit-zone: 8%;
          
          -moz-hyphens: auto;
          -moz-hyphenate-limit-chars: 6 3 3;
          -moz-hyphenate-limit-lines: 2;
          -moz-hyphenate-limit-last: always;
          -moz-hyphenate-limit-zone: 8%;
          
          -ms-hyphens: auto;
          -ms-hyphenate-limit-chars: 6 3 3;
          -ms-hyphenate-limit-lines: 2;
          -ms-hyphenate-limit-last: always;
          -ms-hyphenate-limit-zone: 8%;
          
          hyphens: auto;
          hyphenate-limit-chars: 6 3 3;
          hyphenate-limit-lines: 2;
          hyphenate-limit-last: always;
          hyphenate-limit-zone: 8%;
      }
    </style>

    <title>Differentiable Diffusion for Dense Depth Estimation from Multi-view Images</title>
  </head>

  <body>
    <div class="container-sm w-75 text-center">
      <h1>Differentiable Diffusion for Dense Depth Estimation from Multi-view Images</h1>
      <h4>CVPR 2021</h4>
      
      <br>
      <div class="row d-flex justify-content-center">
        <div class="col-3">
          <a href="https://cs.brown.edu/~nkhan6">Numair Khan</a></br>
          Brown University
        </div>
        
        <div class="col-3">
          <a href="http://vclab.kaist.ac.kr/minhkim/">Min H. Kim</a></br>
          KAIST
        </div>

        <div class="col-3">
          <a href="http://www.jamestompkin.com">James Tompkin</a></br>
          Brown University
        </div>
      </div>
    </div>
    
    <br>
    <br>
    <div class="container w-50">
      <div class="row d-flex justify-content-center">
        <div class="col-2">
        <a href="docs/khan2021_diffdiffdepth.pdf"><img src="img/pdf-logo.png" width=100% onmouseover="this.src='img/pdf-logo-over.png'" onmouseout="this.src='img/pdf-logo.png'"/></a>
        <br>
        <div style="text-align:center">Paper</div>
        </div>
        <div class="col-2">
        <a href="docs/khan2021_diffdiffdepth_supp.pdf"><img src="img/pdf-logo.png" width=100% onmouseover="this.src='img/pdf-logo-over.png'" onmouseout="this.src='img/pdf-logo.png'"/></a>
        <br>
        <div style="text-align:center">Suppl</div>
        </div>
        <div class="col-2">
        <a href="http://arxiv.org/abs/2106.08917"><img src="img/arXiv-logo.png" width=100% onmouseover="this.src='img/arXiv-logo-over.png'" onmouseout="this.src='img/arXiv-logo.png'"/></a>
        <br>
        <div style="text-align:center">arXiv</div>
        </div>
        <div class="col-2">
        <a href="https://github.com/brownvc/diffdiffdepth"><img src="img/github-logo.png" width=100% onmouseover="this.src='img/github-logo-over.png'" onmouseout="this.src='img/github-logo.png'"/></a>
        <br>
        <div style="text-align:center">Code</div>
        </div>
        <div class="col-2">
        <a href="./video/diffdiffdepth_cvpr2021.mp4"><img src="img/video-logo.png" width=100% onmouseover="this.src='img/video-logo-over.png'" onmouseout="this.src='img/video-logo.png'"/></a>
        <br>
        <div style="text-align:center">Video</div>
        </div>
      </div>
    </div>
    
    <br>
    <br>
    <div class="container w-50">
      <div class="row">
        <div class="col-sm-6 d-flex justify-content-center">
          <img src="img/teaser_dino_rgb.png" width=100%>
        </div>
        <div class="col-sm-6 d-flex justify-content-center">
          <img src="img/teaser_dino_depth.gif" width=100%>
        </div>
      </div>
      <div class="row">
        <div class="col-sm-6 d-flex justify-content-center">
          <img src="img/teaser_lego_rgb.png" width=100%>
        </div>
        <div class="col-sm-6 d-flex justify-content-center">
          <img src="img/teaser_lego_depth.gif" width=100%>
        </div>
      </div>
    </div>
    
    <div class="container-sm w-50">
      <h3>Abstract</h3>
      <p>
      We present a method to estimate dense depth by optimizing a sparse set of points such that their diffusion into a depth map minimizes a multi-view reprojection error from RGB supervision. We optimize point positions, depths, and weights with respect to the loss by differential splatting that models points as Gaussians with analytic transmittance. Further, we develop an efficient optimization routine that can simultaneously optimize the 50k+ points required for complex scene reconstruction. We validate our routine using ground truth data and show high reconstruction quality. Then, we apply this to light field and wider baseline images via self supervision, and show improvements in both average and outlier error for depth maps diffused from inaccurate sparse points. Finally, we compare qualitative and quantitative results to image processing and deep learning methods.
      </p>
    </div>

    <div class="container w-50">
      <h3>Citation</h3>
      <div class="monospace" style="background-color:rgba(230, 230, 230, 1.0); padding:20px">
        @inproceedings{khan2021diffdiffdepth, </br>
        <div style="margin-left: 40px">
          title={Differentiable Diffusion for Dense Depth Estimation from Multi-view Images}, </br>
          author={Numair Khan and Min H. Kim and James Tompkin}, </br>
          booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, </br>
          year={2021} </br>
        </div>
        }
      </br>
      </div>
    </div>

    <div class="container w-50">
      <h3>Presentation Video</h3>
      <video src="./video/diffdiffdepth_cvpr2021.mp4" width="100%" controls></video>
    </div>

    <div class="container w-50">
      <h3>Related Projects</h3>
      <ul>
        <li><a href="http://visual.cs.brown.edu/lightfielddepth/">4D Light Field Depth Estimation</a>&mdash;Efficient sparse estimation and view-consistent diffusion.</li>
        <li><a href="https://github.com/brownvc/lightfieldsuperpixels/">4D Light Field Superpixels</a>&mdash;View-consistent and occlusion-aware estimation.</li>
      </ul>
    </div>

    <div class="container w-50">
      <h3>Acknowledgements</h3>
      <p>
        We thank the reviewers for their detailed feedback. Numair Khan thanks an Andy van Dam PhD Fellowship, and Min H. Kim acknowledges the support of Korea NRF grant (2019R1A2C3007229)
      </p>

      <div class="row">
        <div class="col-6 d-flex justify-content-center">
          <a href="http://visual.cs.brown.edu/"><img src="./img/logos/BrownCSLogo.png" width="100%"></a>
        </div>
        <div class="col-6 d-flex justify-content-center">
          <img src="./img/logos/KAISTlogo.png" width="50%">
        </div>
      </div>
    </div>

    </br>
    </br>
    </br>
    
  </body>

</html>
